{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DESKTOP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "Running on public URL: https://e10774444da90ade0e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e10774444da90ade0e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import time\n",
    "\n",
    "# GPU 사용 여부 확인 및 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# 음악 설명 생성\n",
    "def generate_response(mood, genre, elements, tempo):\n",
    "    description = f\"현재 기분: {mood}, 선호하는 음악 장르: {genre}, 음악 요소: {elements}, 분위기/속도: {tempo}\"\n",
    "    full_prompt = f\"\"\"\n",
    "    당신은 ADHD 환자를 위한 음악 설명을 작성하는 어시스턴트입니다. \n",
    "    사용자의 입력을 바탕으로 음악 설명을 작성해야 합니다.\n",
    "    사용자의 기분, 상황, 선호 장르, 분위기/속도에 맞춰 집중력을 향상시키고 스트레스를 감소시키는 음악의 설명을 작성해주세요.\n",
    "    음악 설명은 다음의 예시의 형식대로 작성해야 합니다. \n",
    "\n",
    "    ## 예시\n",
    "    이 음악은 차분하고 느린 템포의 클래식 음악으로, 바쁜 일상 속에서 집중력을 높이고 스트레스를 줄이는 데 도움을 줄 수 있습니다. \n",
    "    피아노와 바이올린의 부드러운 선율이 조화를 이루며, 마음을 편안하게 해줍니다. \n",
    "    특히 바흐의 '골드베르크 변주곡'처럼 복잡하지 않으면서도 집중력을 향상시키는 음악이 이상적입니다. \n",
    "    이 음악을 들으면 중요한 프로젝트를 완성하는 동안 마음의 안정을 찾고, 차분하게 일에 몰두할 수 있을 것입니다.\n",
    "\n",
    "    {description}\n",
    "    \"\"\"\n",
    "    result = llm([HumanMessage(content=full_prompt)])\n",
    "    \n",
    "    if hasattr(result, 'content'):\n",
    "        return result.content\n",
    "    elif hasattr(result, 'text'):\n",
    "        return result.text\n",
    "    else:\n",
    "        return \"No text content found in the response.\"\n",
    "\n",
    "# 음악 생성 모델을 위한 음악 설명 요약 및 번역\n",
    "def music_features(response):\n",
    "    summary_prompt = f\"\"\"\n",
    "    요약: 이 음악 설명에서 음악의 특징적인 부분만을 30자 이내로 간략하게 서술해주세요. \n",
    "    음악을 통해 얻을 수 있는 효과는 제거하고, 음악적 특성만을 서술해주세요. \n",
    "    답변은 영어로 출력합니다. \n",
    "    아래의 형식처럼 음악의 특성만을 고려하여 작성하고, 한 줄로 출력해주세요.\n",
    "\n",
    "    출력 형식:\n",
    "    a catchy beat for a podcast intro\n",
    "    \n",
    "    예시: \n",
    "    1. a catchy beat for a podcast intro\n",
    "    2. a funky house with 80s hip hop vibes\n",
    "    3. a chill song with influences from lofi, chillstep and downtempo\n",
    "    \\n\\n'{response}'\"\"\"\n",
    "    # 요약 요청을 모델에 전달\n",
    "    summary_result = llm([HumanMessage(content=summary_prompt)])\n",
    "    return summary_result\n",
    "\n",
    "# 음악 생성 모델 초기화\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
    "\n",
    "def generate_music(summary, directory=\"./\", duration_seconds=30):\n",
    "    # Musicgen 모델을 사용하여 음악 생성\n",
    "    inputs = processor(text=[summary], padding=True, return_tensors=\"pt\")\n",
    "    audio_values = model.generate(**inputs, max_new_tokens=256)\n",
    "    sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "    \n",
    "    # 파일 저장\n",
    "    output_filename = f\"{directory}music.wav\"\n",
    "    scipy.io.wavfile.write(output_filename, rate=sampling_rate, data=audio_values[0, 0].numpy())\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "# Gradio 인터페이스용 통합 함수\n",
    "def gradio_music_therapy(mood, genre, elements, tempo, duration_seconds):\n",
    "    response = generate_response(mood, genre, elements, tempo)\n",
    "    summary = music_features(response).content\n",
    "    music_file = generate_music(summary, duration_seconds=duration_seconds)\n",
    "    return response, music_file\n",
    "\n",
    "#예제\n",
    "def print_like_dislike(x: gr.LikeData):\n",
    "    print(x.index, x.value, x.liked)\n",
    "\n",
    "def add_message(history, message):\n",
    "    history.append((message, None))\n",
    "    return history, gr.Textbox(value=None, interactive=False)\n",
    "\n",
    "def bot(history):\n",
    "    response = \"**That's cool!**\"\n",
    "    history[-1][1] = \"\"\n",
    "    for character in response:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.05)\n",
    "        yield history\n",
    "\n",
    "\n",
    "def meal_planner(time_of_day, meal_options):\n",
    "    return f\"{time_of_day}에는 {' 그리고 '.join(meal_options)}을(를) 드세요.\"\n",
    "\n",
    "# Gradio Blocks를 사용하여 인터페이스 설정\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 성인 ADHD 진단 및 치료를 위한 상담 챗봇: ETA bot\")\n",
    "    gr.Markdown(\"#### ADHD를 위한 자가진단 및 치료 챗봇입니다. 자가진단을 통해 ADHD 결과를 분석하고, 병원 치료 혹은 음악 치료를 받을 수 있습니다.\")\n",
    "    with gr.Tabs():\n",
    "        \n",
    "        # ADHD 자가진단 챗봇 탭\n",
    "        with gr.TabItem(\"ADHD 자가진단 챗봇\"):\n",
    "            chatbot = gr.Chatbot(\n",
    "                [],\n",
    "                elem_id=\"chatbot\",\n",
    "                bubble_full_width=False\n",
    "            )\n",
    "\n",
    "            chat_input = gr.Textbox(interactive=True, \n",
    "            placeholder=\"ADHD를 위한 자가진단 및 치료 챗봇입니다. 자가진단을 통해 ADHD 결과를 분석하고, 병원 치료 혹은 음악 치료를 받을 수 있습니다. 궁금한 점을 질문해주세요!\", \n",
    "            show_label=False)\n",
    "\n",
    "            chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n",
    "            bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n",
    "            bot_msg.then(lambda: gr.Textbox(interactive=True), None, [chat_input])\n",
    "\n",
    "            chatbot.like(print_like_dislike, None, None)\n",
    "\n",
    "\n",
    "        with gr.TabItem(\"ADHD 치료 음악 생성\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    mood_input = gr.Textbox(label=\"현재 기분 또는 상황\", placeholder=\"예: 행복, 스트레스 받음 등\")\n",
    "                    genre_input = gr.Textbox(label=\"선호하는 음악 장르\", placeholder=\"예: 클래식, 재즈 등\")\n",
    "                    elements_input = gr.Textbox(label=\"음악에 반영되었으면 하는 요소\", placeholder=\"예: 자연 소리, 특정 악기 등\")\n",
    "                    tempo_input = gr.Textbox(label=\"원하는 음악의 분위기나 속도\", placeholder=\"예: 차분하고 느린, 에너지 넘치는 등\")\n",
    "                    duration_input = gr.Slider(minimum=1, maximum=120, step=1, label=\"음악 길이 (초 단위)\", value=30)\n",
    "                    generate_button = gr.Button(\"음악 생성\")\n",
    "                with gr.Column(scale=1):\n",
    "                    music_description_output = gr.Textbox(label=\"생성된 음악 설명\")\n",
    "                    music_file_output = gr.Audio(label=\"생성된 음악 파일\")\n",
    "            generate_button.click(gradio_music_therapy, \n",
    "                                  inputs=[mood_input, genre_input, elements_input, tempo_input, duration_input], \n",
    "                                  outputs=[music_description_output, music_file_output])\n",
    "        \n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
